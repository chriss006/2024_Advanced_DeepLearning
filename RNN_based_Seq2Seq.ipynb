{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM1tTL271tRlSbW6wWE5kbb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chriss006/2024_Advanced_DeepLearning/blob/main/RNN_based_Seq2Seq.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **RNN-based-Seq2Seq for FRA-ENG Translation**"
      ],
      "metadata": {
        "id": "GLrAQxYFgluk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "GFkxv7lfXDcC"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import shutil\n",
        "import zipfile\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import unicodedata\n",
        "import urllib3\n",
        "import requests\n",
        "from tensorflow.keras.layers import Embedding, GRU, Dense\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "headers = {'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}\n",
        "\n",
        "def download_zip(url, output_path):\n",
        "  response = requests.get(url, headers=headers, stream=True)\n",
        "  if response.status_code == 200:\n",
        "    with open(output_path, 'wb') as file:\n",
        "      for chunk in response.iter_content(chunk_size=1024):\n",
        "        file.write(chunk)\n",
        "      print(f'Zip file download to {output_path}')\n",
        "  else:\n",
        "    print(f\"Failed to download the file. Status code: {response.status_code}\")\n",
        "\n",
        "url = 'http://www.manythings.org/anki/fra-eng.zip'\n",
        "output_path = 'fra-eng.zip'\n",
        "download_zip(url, output_path)\n",
        "\n",
        "path = os.getcwd()\n",
        "zipfilename = os.path.join(path, output_path)\n",
        "\n",
        "with zipfile.ZipFile(zipfilename, 'r') as zip_ref:\n",
        "  zip_ref.extractall(path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n32To-lmd9iH",
        "outputId": "65e979b4-95a6-4a4b-bf6b-6a6975b13244"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Zip file download to fra-eng.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_samples = 33000\n",
        "\n",
        "def to_ascii(s):\n",
        "  # 프랑스어 악센트(accent) 삭제\n",
        "  # 예시 : 'déjà diné' -> deja dine\n",
        "  return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
        "                   if unicodedata.category(c) != 'Mn')\n",
        "\n",
        "def preprocess_sentence(sent):\n",
        "  # 악센트 제거 함수 호출\n",
        "  sent = to_ascii(sent.lower())\n",
        "\n",
        "  # 단어와 구두점 사이에 공백 추가.\n",
        "  # ex) \"I am a student.\" => \"I am a student .\"\n",
        "  sent = re.sub(r\"([?.!,¿])\", r\" \\1\", sent)\n",
        "\n",
        "  # (a-z, A-Z, \".\", \"?\", \"!\", \",\") 이들을 제외하고는 전부 공백으로 변환.\n",
        "  sent = re.sub(r\"[^a-zA-Z!.?]+\", r\" \", sent)\n",
        "\n",
        "  # 다수 개의 공백을 하나의 공백으로 치환\n",
        "  sent = re.sub(r\"\\s+\", \" \", sent)\n",
        "  return sent\n",
        "\n",
        "en_sent = u'Have you had dinner?'\n",
        "fr_sent = u'Avez-vous déjà diné?'\n",
        "\n",
        "print('전처리 전 영어 문장: ', en_sent)\n",
        "print('전처리 후 영어 문장: ', preprocess_sentence(en_sent))\n",
        "print('전처리 전 프랑스어 문장: ', fr_sent)\n",
        "print('전처리 후 프랑스어 문장: ', preprocess_sentence(fr_sent))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qToeqa_pe-2U",
        "outputId": "511e3e48-4847-4267-a3d9-de603caf433a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전처리 전 영어 문장:  Have you had dinner?\n",
            "전처리 후 영어 문장:  have you had dinner ?\n",
            "전처리 전 프랑스어 문장:  Avez-vous déjà diné?\n",
            "전처리 후 프랑스어 문장:  avez vous deja dine ?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Hht1JwDJf8w8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}